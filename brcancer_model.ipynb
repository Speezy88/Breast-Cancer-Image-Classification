{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1009,
   "id": "7f84d0dc-2760-4c4e-9727-61c2204a0fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1010,
   "id": "c6745689-1dd8-4516-8729-8ad704804e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BinaryClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_layers):\n",
    "        super(BinaryClassifier, self).__init__()\n",
    "        layers = []\n",
    "        #add fully connected layers with the input dim dividing by two each time the input shape\n",
    "        output_dim = max(3*input_dim//(4), 1)\n",
    "        for i in range(hidden_layers):\n",
    "            i += 1\n",
    "            layers.append(nn.Linear(input_dim,output_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            input_dim = output_dim\n",
    "            output_dim = max(int(input_dim//(0.7)), 1)\n",
    "        #add final layer with sigmiod output and final linear layer\n",
    "        layers.append(nn.Linear(input_dim,1))\n",
    "        #layers.append(nn.Sigmoid())\n",
    "\n",
    "        #create a Seqeuntial implementation, no additional layers but provides one line to run through all layers\n",
    "        self.network = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #apply the neural net\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1011,
   "id": "d9eac9af-b0d8-4319-8caf-a2a7f1165b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input shape is not correct\n",
    "input_shape = 30\n",
    "hidden_layers = 6\n",
    "model_1 = BinaryClassifier(input_shape, hidden_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1012,
   "id": "2e869731-8f56-45aa-94c2-5d863d17a300",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1013,
   "id": "a709fd06-93de-491c-8669-2833d1e45d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dataset_to_numpy(dataset: TensorDataset):\n",
    "    X, y = dataset.tensors\n",
    "    # Ensure on CPU and detached from computation graph\n",
    "    X_np = X.detach().numpy()\n",
    "    y_np = y.detach().numpy()\n",
    "    return X_np, y_np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1014,
   "id": "feb01e77-fa34-4d87-9fcb-a387ea83a9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    # Read data\n",
    "    df = pd.read_csv('br_cancer_normalized.csv', encoding='latin-1')\n",
    "\n",
    "    # Separate features and labels\n",
    "    X = df.drop(columns=['Diagnosis']).to_numpy()\n",
    "    y = df['Diagnosis'].to_numpy()\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1015,
   "id": "5bb6fce4-8c15-465e-94b2-38db0ff0e49c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30) (569,)\n"
     ]
    }
   ],
   "source": [
    "#import whatever data loader function is needed\n",
    "#should output train dataloader and test dataloader  as the full train and test datasets\n",
    "X_np, y_np = load_data()\n",
    "print(X_np.shape, y_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1016,
   "id": "14087969-d4e1-4e9b-b1cd-f85c7a32187c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count positives and negatives\n",
    "num_pos = (y_np == 1).sum().item()\n",
    "num_neg = (y_np == 0).sum().item()\n",
    "\n",
    "# Compute base pos_weight\n",
    "base_pos_weight = num_neg / num_pos\n",
    "\n",
    "# Increase penalty for missing a 1 by 20%\n",
    "pos_weight_value = torch.tensor(base_pos_weight*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1017,
   "id": "e57e0389-d588-4891-8b1d-e3d15d6030a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model_1.parameters(), lr=1e-3)\n",
    "loss_fn = nn.BCEWithLogitsLoss(pos_weight=pos_weight_value * 1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1018,
   "id": "d4d79320-29a4-4595-b21b-2ec513108877",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def visualize_prediction_distribution(model, dataloader, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Visualize the percentage of predicted 0s and 1s from a binary classifier.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained PyTorch model\n",
    "        dataloader: DataLoader containing your dataset\n",
    "        threshold: Decision threshold for classification (default=0.5)\n",
    "        device: \"cpu\" or \"cuda\"\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_X, _ in dataloader:\n",
    "            outputs = model(batch_X).squeeze()\n",
    "            \n",
    "            # If model ends with Sigmoid\n",
    "            if outputs.dim() == 0:\n",
    "                outputs = outputs.unsqueeze(0)\n",
    "            \n",
    "            predicted = (outputs >= threshold).int().cpu().numpy()\n",
    "            preds.extend(predicted)\n",
    "    \n",
    "    preds = np.array(preds)\n",
    "    total = len(preds)\n",
    "    percent_0 = (preds == 0).sum() / total * 100\n",
    "    percent_1 = (preds == 1).sum() / total * 100\n",
    "    print(percent_0, \"this is percent 0\")\n",
    "    # # Bar plot\n",
    "    # plt.bar([\"Predicted 0\", \"Predicted 1\"], [percent_0, percent_1], color=[\"skyblue\", \"salmon\"])\n",
    "    # plt.ylabel(\"Percentage (%)\")\n",
    "    # plt.title(\"Prediction Distribution\")\n",
    "    # plt.show()\n",
    "    \n",
    "    print(f\"Predicted 0: {percent_0:.2f}%\")\n",
    "    print(f\"Predicted 1: {percent_1:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1019,
   "id": "79b0bfe9-a790-433e-b0c2-98f67df1ca63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean, stdev\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import linear_model\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1020,
   "id": "120b0c90-358e-4ee5-9fcb-40e2e6511666",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import copy\n",
    "\n",
    "def test(model, data, criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in data:\n",
    "            batch_y = batch_y.unsqueeze(1)\n",
    "            logits = model(batch_X)\n",
    "            loss = criterion(logits, batch_y)\n",
    "            test_loss += loss.item() * batch_X.size(0)\n",
    "\n",
    "            preds = (torch.sigmoid(logits) >= 0.5).float()\n",
    "            correct += (preds == batch_y).sum().item()\n",
    "            total += batch_y.size(0)\n",
    "    \n",
    "    avg_loss = test_loss / total\n",
    "    accuracy = correct / total\n",
    "    print(f\"Test Loss: {avg_loss:.4f} | Test Acc: {accuracy:.4f}\")\n",
    "    return avg_loss, accuracy\n",
    "    \n",
    "\n",
    "def train_with_stratified_kfold(X, y, model_fn, input_shape, hidden_layers, batch_size=32, lr=1e-3, k_folds=5, num_epochs=100):\n",
    "    # Wrap into dataset\n",
    "    dataset = TensorDataset(torch.tensor(X, dtype=torch.float32),\n",
    "                            torch.tensor(y, dtype=torch.float32))\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=k_folds, shuffle=True)\n",
    "    all_fold_results = []\n",
    "    models = []\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "        print(f\"\\n--- Fold {fold+1} ---\")\n",
    "\n",
    "        train_subset = Subset(dataset, train_idx)\n",
    "        val_subset = Subset(dataset, val_idx)\n",
    "\n",
    "        train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
    "     # fresh model for each fold\n",
    "        cur_model = BinaryClassifier(30,5)\n",
    "        criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight_value * 1.05)\n",
    "        optimizer = optim.Adam(cur_model.parameters(), lr=lr)\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            cur_model.train()\n",
    "            epoch_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "\n",
    "            for batch_X, batch_y in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = cur_model(batch_X).squeeze()\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                epoch_loss += loss.item() * batch_X.size(0)\n",
    "                preds = (torch.sigmoid(outputs) >= 0.5).float()\n",
    "                correct += (preds == batch_y).sum().item()\n",
    "                total += batch_y.size(0)\n",
    "\n",
    "            train_acc = correct / total\n",
    "            train_loss = epoch_loss / total\n",
    "            print(f\"Epoch {epoch+1}: Train Loss {train_loss:.4f} | Train Acc {train_acc:.4f}\")\n",
    "\n",
    "        avg_loss, accuracy = test(cur_model, val_loader, criterion)\n",
    "        all_fold_results.append((avg_loss, accuracy))\n",
    "        models.append(cur_model)\n",
    "        visualize_prediction_distribution(cur_model, val_loader)\n",
    "\n",
    "    \n",
    "    return all_fold_results , models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1021,
   "id": "fa0686e2-3cfa-41f4-b8da-25d7009c2650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Fold 1 ---\n",
      "Epoch 1: Train Loss 1.3572 | Train Acc 0.5099\n",
      "Epoch 2: Train Loss 1.2737 | Train Acc 0.3736\n",
      "Epoch 3: Train Loss 1.1690 | Train Acc 0.3736\n",
      "Epoch 4: Train Loss 1.0877 | Train Acc 0.3736\n",
      "Epoch 5: Train Loss 0.9454 | Train Acc 0.3736\n",
      "Epoch 6: Train Loss 0.7388 | Train Acc 0.4242\n",
      "Epoch 7: Train Loss 0.5802 | Train Acc 0.8418\n",
      "Epoch 8: Train Loss 0.4566 | Train Acc 0.8945\n",
      "Epoch 9: Train Loss 0.3287 | Train Acc 0.9209\n",
      "Epoch 10: Train Loss 0.2435 | Train Acc 0.9341\n",
      "Epoch 11: Train Loss 0.2680 | Train Acc 0.9451\n",
      "Epoch 12: Train Loss 0.1915 | Train Acc 0.9363\n",
      "Epoch 13: Train Loss 0.1903 | Train Acc 0.9516\n",
      "Epoch 14: Train Loss 0.1961 | Train Acc 0.9538\n",
      "Epoch 15: Train Loss 0.1510 | Train Acc 0.9626\n",
      "Epoch 16: Train Loss 0.1456 | Train Acc 0.9560\n",
      "Epoch 17: Train Loss 0.1684 | Train Acc 0.9648\n",
      "Epoch 18: Train Loss 0.1573 | Train Acc 0.9648\n",
      "Epoch 19: Train Loss 0.1325 | Train Acc 0.9736\n",
      "Epoch 20: Train Loss 0.1618 | Train Acc 0.9692\n",
      "Epoch 21: Train Loss 0.1532 | Train Acc 0.9582\n",
      "Epoch 22: Train Loss 0.1379 | Train Acc 0.9714\n",
      "Epoch 23: Train Loss 0.1543 | Train Acc 0.9692\n",
      "Epoch 24: Train Loss 0.1306 | Train Acc 0.9736\n",
      "Epoch 25: Train Loss 0.1368 | Train Acc 0.9758\n",
      "Epoch 26: Train Loss 0.1249 | Train Acc 0.9692\n",
      "Epoch 27: Train Loss 0.1636 | Train Acc 0.9560\n",
      "Epoch 28: Train Loss 0.1886 | Train Acc 0.9714\n",
      "Epoch 29: Train Loss 0.1384 | Train Acc 0.9780\n",
      "Epoch 30: Train Loss 0.1419 | Train Acc 0.9604\n",
      "Epoch 31: Train Loss 0.1347 | Train Acc 0.9692\n",
      "Epoch 32: Train Loss 0.1286 | Train Acc 0.9824\n",
      "Epoch 33: Train Loss 0.2073 | Train Acc 0.9407\n",
      "Epoch 34: Train Loss 0.1268 | Train Acc 0.9714\n",
      "Epoch 35: Train Loss 0.1170 | Train Acc 0.9802\n",
      "Epoch 36: Train Loss 0.1266 | Train Acc 0.9736\n",
      "Epoch 37: Train Loss 0.1249 | Train Acc 0.9780\n",
      "Epoch 38: Train Loss 0.1244 | Train Acc 0.9670\n",
      "Epoch 39: Train Loss 0.1178 | Train Acc 0.9780\n",
      "Epoch 40: Train Loss 0.1123 | Train Acc 0.9890\n",
      "Epoch 41: Train Loss 0.1068 | Train Acc 0.9692\n",
      "Epoch 42: Train Loss 0.1403 | Train Acc 0.9802\n",
      "Epoch 43: Train Loss 0.1296 | Train Acc 0.9780\n",
      "Epoch 44: Train Loss 0.1484 | Train Acc 0.9604\n",
      "Epoch 45: Train Loss 0.1382 | Train Acc 0.9582\n",
      "Epoch 46: Train Loss 0.1284 | Train Acc 0.9714\n",
      "Epoch 47: Train Loss 0.1213 | Train Acc 0.9824\n",
      "Epoch 48: Train Loss 0.1097 | Train Acc 0.9780\n",
      "Epoch 49: Train Loss 0.1180 | Train Acc 0.9692\n",
      "Epoch 50: Train Loss 0.1114 | Train Acc 0.9780\n",
      "Epoch 51: Train Loss 0.1180 | Train Acc 0.9736\n",
      "Epoch 52: Train Loss 0.1149 | Train Acc 0.9758\n",
      "Epoch 53: Train Loss 0.1113 | Train Acc 0.9890\n",
      "Epoch 54: Train Loss 0.0991 | Train Acc 0.9714\n",
      "Epoch 55: Train Loss 0.1122 | Train Acc 0.9824\n",
      "Epoch 56: Train Loss 0.1013 | Train Acc 0.9758\n",
      "Epoch 57: Train Loss 0.1115 | Train Acc 0.9802\n",
      "Epoch 58: Train Loss 0.0953 | Train Acc 0.9736\n",
      "Epoch 59: Train Loss 0.1107 | Train Acc 0.9824\n",
      "Epoch 60: Train Loss 0.1184 | Train Acc 0.9736\n",
      "Epoch 61: Train Loss 0.1104 | Train Acc 0.9802\n",
      "Epoch 62: Train Loss 0.1059 | Train Acc 0.9780\n",
      "Epoch 63: Train Loss 0.1072 | Train Acc 0.9824\n",
      "Epoch 64: Train Loss 0.0935 | Train Acc 0.9758\n",
      "Epoch 65: Train Loss 0.1004 | Train Acc 0.9846\n",
      "Epoch 66: Train Loss 0.1131 | Train Acc 0.9736\n",
      "Epoch 67: Train Loss 0.0925 | Train Acc 0.9802\n",
      "Epoch 68: Train Loss 0.0973 | Train Acc 0.9912\n",
      "Epoch 69: Train Loss 0.1222 | Train Acc 0.9758\n",
      "Epoch 70: Train Loss 0.1056 | Train Acc 0.9780\n",
      "Epoch 71: Train Loss 0.0985 | Train Acc 0.9802\n",
      "Epoch 72: Train Loss 0.1256 | Train Acc 0.9604\n",
      "Epoch 73: Train Loss 0.1461 | Train Acc 0.9736\n",
      "Epoch 74: Train Loss 0.1275 | Train Acc 0.9824\n",
      "Epoch 75: Train Loss 0.1102 | Train Acc 0.9780\n",
      "Epoch 76: Train Loss 0.0954 | Train Acc 0.9846\n",
      "Epoch 77: Train Loss 0.0939 | Train Acc 0.9802\n",
      "Epoch 78: Train Loss 0.0960 | Train Acc 0.9824\n",
      "Epoch 79: Train Loss 0.0928 | Train Acc 0.9846\n",
      "Epoch 80: Train Loss 0.0891 | Train Acc 0.9802\n",
      "Epoch 81: Train Loss 0.1504 | Train Acc 0.9692\n",
      "Epoch 82: Train Loss 0.1145 | Train Acc 0.9890\n",
      "Epoch 83: Train Loss 0.0890 | Train Acc 0.9802\n",
      "Epoch 84: Train Loss 0.1039 | Train Acc 0.9890\n",
      "Epoch 85: Train Loss 0.0868 | Train Acc 0.9824\n",
      "Epoch 86: Train Loss 0.0896 | Train Acc 0.9868\n",
      "Epoch 87: Train Loss 0.0817 | Train Acc 0.9868\n",
      "Epoch 88: Train Loss 0.0861 | Train Acc 0.9890\n",
      "Epoch 89: Train Loss 0.0843 | Train Acc 0.9846\n",
      "Epoch 90: Train Loss 0.0931 | Train Acc 0.9868\n",
      "Epoch 91: Train Loss 0.0903 | Train Acc 0.9890\n",
      "Epoch 92: Train Loss 0.0808 | Train Acc 0.9868\n",
      "Epoch 93: Train Loss 0.0803 | Train Acc 0.9890\n",
      "Epoch 94: Train Loss 0.1476 | Train Acc 0.9604\n",
      "Epoch 95: Train Loss 0.1264 | Train Acc 0.9758\n",
      "Epoch 96: Train Loss 0.0838 | Train Acc 0.9912\n",
      "Epoch 97: Train Loss 0.0758 | Train Acc 0.9868\n",
      "Epoch 98: Train Loss 0.0947 | Train Acc 0.9780\n",
      "Epoch 99: Train Loss 0.0842 | Train Acc 0.9890\n",
      "Epoch 100: Train Loss 0.0757 | Train Acc 0.9890\n",
      "Test Loss: 0.2084 | Test Acc: 0.9737\n",
      "62.28070175438597 this is percent 0\n",
      "Predicted 0: 62.28%\n",
      "Predicted 1: 37.72%\n",
      "\n",
      "--- Fold 2 ---\n",
      "Epoch 1: Train Loss 1.3450 | Train Acc 0.5209\n",
      "Epoch 2: Train Loss 1.2886 | Train Acc 0.3736\n",
      "Epoch 3: Train Loss 1.1862 | Train Acc 0.3736\n",
      "Epoch 4: Train Loss 0.9751 | Train Acc 0.3736\n",
      "Epoch 5: Train Loss 0.6804 | Train Acc 0.6264\n",
      "Epoch 6: Train Loss 0.4897 | Train Acc 0.9077\n",
      "Epoch 7: Train Loss 0.3950 | Train Acc 0.9209\n",
      "Epoch 8: Train Loss 0.2652 | Train Acc 0.9297\n",
      "Epoch 9: Train Loss 0.2360 | Train Acc 0.9473\n",
      "Epoch 10: Train Loss 0.2144 | Train Acc 0.9516\n",
      "Epoch 11: Train Loss 0.2054 | Train Acc 0.9473\n",
      "Epoch 12: Train Loss 0.1805 | Train Acc 0.9495\n",
      "Epoch 13: Train Loss 0.1818 | Train Acc 0.9626\n",
      "Epoch 14: Train Loss 0.2099 | Train Acc 0.9495\n",
      "Epoch 15: Train Loss 0.2246 | Train Acc 0.9363\n",
      "Epoch 16: Train Loss 0.1616 | Train Acc 0.9560\n",
      "Epoch 17: Train Loss 0.1579 | Train Acc 0.9648\n",
      "Epoch 18: Train Loss 0.1663 | Train Acc 0.9538\n",
      "Epoch 19: Train Loss 0.1523 | Train Acc 0.9648\n",
      "Epoch 20: Train Loss 0.1519 | Train Acc 0.9604\n",
      "Epoch 21: Train Loss 0.1513 | Train Acc 0.9736\n",
      "Epoch 22: Train Loss 0.1584 | Train Acc 0.9670\n",
      "Epoch 23: Train Loss 0.1393 | Train Acc 0.9736\n",
      "Epoch 24: Train Loss 0.1318 | Train Acc 0.9758\n",
      "Epoch 25: Train Loss 0.1776 | Train Acc 0.9538\n",
      "Epoch 26: Train Loss 0.1310 | Train Acc 0.9714\n",
      "Epoch 27: Train Loss 0.1350 | Train Acc 0.9692\n",
      "Epoch 28: Train Loss 0.1333 | Train Acc 0.9714\n",
      "Epoch 29: Train Loss 0.1419 | Train Acc 0.9648\n",
      "Epoch 30: Train Loss 0.1281 | Train Acc 0.9758\n",
      "Epoch 31: Train Loss 0.1278 | Train Acc 0.9714\n",
      "Epoch 32: Train Loss 0.1233 | Train Acc 0.9692\n",
      "Epoch 33: Train Loss 0.1283 | Train Acc 0.9736\n",
      "Epoch 34: Train Loss 0.1238 | Train Acc 0.9714\n",
      "Epoch 35: Train Loss 0.1359 | Train Acc 0.9692\n",
      "Epoch 36: Train Loss 0.1357 | Train Acc 0.9736\n",
      "Epoch 37: Train Loss 0.2281 | Train Acc 0.9451\n",
      "Epoch 38: Train Loss 0.1246 | Train Acc 0.9670\n",
      "Epoch 39: Train Loss 0.1234 | Train Acc 0.9736\n",
      "Epoch 40: Train Loss 0.1228 | Train Acc 0.9758\n",
      "Epoch 41: Train Loss 0.1154 | Train Acc 0.9758\n",
      "Epoch 42: Train Loss 0.1135 | Train Acc 0.9736\n",
      "Epoch 43: Train Loss 0.1147 | Train Acc 0.9824\n",
      "Epoch 44: Train Loss 0.1213 | Train Acc 0.9736\n",
      "Epoch 45: Train Loss 0.1164 | Train Acc 0.9714\n",
      "Epoch 46: Train Loss 0.1244 | Train Acc 0.9626\n",
      "Epoch 47: Train Loss 0.1349 | Train Acc 0.9736\n",
      "Epoch 48: Train Loss 0.1249 | Train Acc 0.9736\n",
      "Epoch 49: Train Loss 0.1335 | Train Acc 0.9714\n",
      "Epoch 50: Train Loss 0.1110 | Train Acc 0.9824\n",
      "Epoch 51: Train Loss 0.1190 | Train Acc 0.9780\n",
      "Epoch 52: Train Loss 0.1068 | Train Acc 0.9736\n",
      "Epoch 53: Train Loss 0.1090 | Train Acc 0.9758\n",
      "Epoch 54: Train Loss 0.1049 | Train Acc 0.9714\n",
      "Epoch 55: Train Loss 0.1567 | Train Acc 0.9670\n",
      "Epoch 56: Train Loss 0.1283 | Train Acc 0.9692\n",
      "Epoch 57: Train Loss 0.1079 | Train Acc 0.9802\n",
      "Epoch 58: Train Loss 0.1549 | Train Acc 0.9626\n",
      "Epoch 59: Train Loss 0.1145 | Train Acc 0.9692\n",
      "Epoch 60: Train Loss 0.1161 | Train Acc 0.9802\n",
      "Epoch 61: Train Loss 0.1438 | Train Acc 0.9670\n",
      "Epoch 62: Train Loss 0.1051 | Train Acc 0.9736\n",
      "Epoch 63: Train Loss 0.1045 | Train Acc 0.9736\n",
      "Epoch 64: Train Loss 0.1035 | Train Acc 0.9758\n",
      "Epoch 65: Train Loss 0.1125 | Train Acc 0.9758\n",
      "Epoch 66: Train Loss 0.1095 | Train Acc 0.9758\n",
      "Epoch 67: Train Loss 0.0993 | Train Acc 0.9714\n",
      "Epoch 68: Train Loss 0.0984 | Train Acc 0.9736\n",
      "Epoch 69: Train Loss 0.1064 | Train Acc 0.9714\n",
      "Epoch 70: Train Loss 0.0967 | Train Acc 0.9758\n",
      "Epoch 71: Train Loss 0.0954 | Train Acc 0.9846\n",
      "Epoch 72: Train Loss 0.1145 | Train Acc 0.9758\n",
      "Epoch 73: Train Loss 0.1209 | Train Acc 0.9714\n",
      "Epoch 74: Train Loss 0.0982 | Train Acc 0.9758\n",
      "Epoch 75: Train Loss 0.1002 | Train Acc 0.9824\n",
      "Epoch 76: Train Loss 0.1005 | Train Acc 0.9824\n",
      "Epoch 77: Train Loss 0.1009 | Train Acc 0.9758\n",
      "Epoch 78: Train Loss 0.0903 | Train Acc 0.9780\n",
      "Epoch 79: Train Loss 0.1047 | Train Acc 0.9802\n",
      "Epoch 80: Train Loss 0.1022 | Train Acc 0.9780\n",
      "Epoch 81: Train Loss 0.0928 | Train Acc 0.9846\n",
      "Epoch 82: Train Loss 0.0931 | Train Acc 0.9802\n",
      "Epoch 83: Train Loss 0.0877 | Train Acc 0.9824\n",
      "Epoch 84: Train Loss 0.1271 | Train Acc 0.9780\n",
      "Epoch 85: Train Loss 0.1034 | Train Acc 0.9670\n",
      "Epoch 86: Train Loss 0.1211 | Train Acc 0.9714\n",
      "Epoch 87: Train Loss 0.0909 | Train Acc 0.9780\n",
      "Epoch 88: Train Loss 0.0890 | Train Acc 0.9846\n",
      "Epoch 89: Train Loss 0.0876 | Train Acc 0.9824\n",
      "Epoch 90: Train Loss 0.0955 | Train Acc 0.9780\n",
      "Epoch 91: Train Loss 0.0946 | Train Acc 0.9780\n",
      "Epoch 92: Train Loss 0.0956 | Train Acc 0.9780\n",
      "Epoch 93: Train Loss 0.0855 | Train Acc 0.9780\n",
      "Epoch 94: Train Loss 0.1277 | Train Acc 0.9714\n",
      "Epoch 95: Train Loss 0.2618 | Train Acc 0.9495\n",
      "Epoch 96: Train Loss 0.1472 | Train Acc 0.9758\n",
      "Epoch 97: Train Loss 0.1471 | Train Acc 0.9604\n",
      "Epoch 98: Train Loss 0.1340 | Train Acc 0.9736\n",
      "Epoch 99: Train Loss 0.1193 | Train Acc 0.9736\n",
      "Epoch 100: Train Loss 0.0974 | Train Acc 0.9780\n",
      "Test Loss: 0.1321 | Test Acc: 0.9825\n",
      "63.1578947368421 this is percent 0\n",
      "Predicted 0: 63.16%\n",
      "Predicted 1: 36.84%\n",
      "\n",
      "--- Fold 3 ---\n",
      "Epoch 1: Train Loss 1.3035 | Train Acc 0.3714\n",
      "Epoch 2: Train Loss 1.2439 | Train Acc 0.3714\n",
      "Epoch 3: Train Loss 1.1615 | Train Acc 0.3714\n",
      "Epoch 4: Train Loss 1.0754 | Train Acc 0.3714\n",
      "Epoch 5: Train Loss 0.9042 | Train Acc 0.3714\n",
      "Epoch 6: Train Loss 0.6534 | Train Acc 0.6549\n",
      "Epoch 7: Train Loss 0.4641 | Train Acc 0.9033\n",
      "Epoch 8: Train Loss 0.3077 | Train Acc 0.9297\n",
      "Epoch 9: Train Loss 0.2620 | Train Acc 0.9319\n",
      "Epoch 10: Train Loss 0.2175 | Train Acc 0.9495\n",
      "Epoch 11: Train Loss 0.2127 | Train Acc 0.9363\n",
      "Epoch 12: Train Loss 0.1910 | Train Acc 0.9516\n",
      "Epoch 13: Train Loss 0.1743 | Train Acc 0.9604\n",
      "Epoch 14: Train Loss 0.1736 | Train Acc 0.9538\n",
      "Epoch 15: Train Loss 0.1611 | Train Acc 0.9582\n",
      "Epoch 16: Train Loss 0.1662 | Train Acc 0.9560\n",
      "Epoch 17: Train Loss 0.2099 | Train Acc 0.9516\n",
      "Epoch 18: Train Loss 0.1953 | Train Acc 0.9516\n",
      "Epoch 19: Train Loss 0.1528 | Train Acc 0.9495\n",
      "Epoch 20: Train Loss 0.1576 | Train Acc 0.9648\n",
      "Epoch 21: Train Loss 0.1539 | Train Acc 0.9714\n",
      "Epoch 22: Train Loss 0.1439 | Train Acc 0.9736\n",
      "Epoch 23: Train Loss 0.1782 | Train Acc 0.9451\n",
      "Epoch 24: Train Loss 0.1381 | Train Acc 0.9670\n",
      "Epoch 25: Train Loss 0.1351 | Train Acc 0.9780\n",
      "Epoch 26: Train Loss 0.1275 | Train Acc 0.9758\n",
      "Epoch 27: Train Loss 0.1378 | Train Acc 0.9648\n",
      "Epoch 28: Train Loss 0.1421 | Train Acc 0.9780\n",
      "Epoch 29: Train Loss 0.1658 | Train Acc 0.9516\n",
      "Epoch 30: Train Loss 0.1346 | Train Acc 0.9538\n",
      "Epoch 31: Train Loss 0.1385 | Train Acc 0.9780\n",
      "Epoch 32: Train Loss 0.1515 | Train Acc 0.9670\n",
      "Epoch 33: Train Loss 0.1241 | Train Acc 0.9780\n",
      "Epoch 34: Train Loss 0.1269 | Train Acc 0.9714\n",
      "Epoch 35: Train Loss 0.1213 | Train Acc 0.9758\n",
      "Epoch 36: Train Loss 0.1261 | Train Acc 0.9758\n",
      "Epoch 37: Train Loss 0.1281 | Train Acc 0.9758\n",
      "Epoch 38: Train Loss 0.1208 | Train Acc 0.9780\n",
      "Epoch 39: Train Loss 0.1195 | Train Acc 0.9758\n",
      "Epoch 40: Train Loss 0.1296 | Train Acc 0.9736\n",
      "Epoch 41: Train Loss 0.1174 | Train Acc 0.9736\n",
      "Epoch 42: Train Loss 0.1196 | Train Acc 0.9846\n",
      "Epoch 43: Train Loss 0.1439 | Train Acc 0.9692\n",
      "Epoch 44: Train Loss 0.1603 | Train Acc 0.9516\n",
      "Epoch 45: Train Loss 0.1151 | Train Acc 0.9824\n",
      "Epoch 46: Train Loss 0.1238 | Train Acc 0.9736\n",
      "Epoch 47: Train Loss 0.1129 | Train Acc 0.9824\n",
      "Epoch 48: Train Loss 0.1202 | Train Acc 0.9692\n",
      "Epoch 49: Train Loss 0.1277 | Train Acc 0.9758\n",
      "Epoch 50: Train Loss 0.1094 | Train Acc 0.9846\n",
      "Epoch 51: Train Loss 0.1119 | Train Acc 0.9802\n",
      "Epoch 52: Train Loss 0.1120 | Train Acc 0.9780\n",
      "Epoch 53: Train Loss 0.1068 | Train Acc 0.9780\n",
      "Epoch 54: Train Loss 0.1106 | Train Acc 0.9824\n",
      "Epoch 55: Train Loss 0.1252 | Train Acc 0.9780\n",
      "Epoch 56: Train Loss 0.1189 | Train Acc 0.9670\n",
      "Epoch 57: Train Loss 0.1474 | Train Acc 0.9780\n",
      "Epoch 58: Train Loss 0.1053 | Train Acc 0.9824\n",
      "Epoch 59: Train Loss 0.1085 | Train Acc 0.9824\n",
      "Epoch 60: Train Loss 0.1109 | Train Acc 0.9846\n",
      "Epoch 61: Train Loss 0.1034 | Train Acc 0.9802\n",
      "Epoch 62: Train Loss 0.1043 | Train Acc 0.9780\n",
      "Epoch 63: Train Loss 0.1309 | Train Acc 0.9670\n",
      "Epoch 64: Train Loss 0.1469 | Train Acc 0.9626\n",
      "Epoch 65: Train Loss 0.1667 | Train Acc 0.9626\n",
      "Epoch 66: Train Loss 0.1187 | Train Acc 0.9868\n",
      "Epoch 67: Train Loss 0.1032 | Train Acc 0.9780\n",
      "Epoch 68: Train Loss 0.1328 | Train Acc 0.9780\n",
      "Epoch 69: Train Loss 0.1475 | Train Acc 0.9736\n",
      "Epoch 70: Train Loss 0.1246 | Train Acc 0.9670\n",
      "Epoch 71: Train Loss 0.1287 | Train Acc 0.9802\n",
      "Epoch 72: Train Loss 0.1000 | Train Acc 0.9802\n",
      "Epoch 73: Train Loss 0.1067 | Train Acc 0.9780\n",
      "Epoch 74: Train Loss 0.1355 | Train Acc 0.9670\n",
      "Epoch 75: Train Loss 0.1069 | Train Acc 0.9780\n",
      "Epoch 76: Train Loss 0.1044 | Train Acc 0.9824\n",
      "Epoch 77: Train Loss 0.1088 | Train Acc 0.9824\n",
      "Epoch 78: Train Loss 0.1001 | Train Acc 0.9802\n",
      "Epoch 79: Train Loss 0.1105 | Train Acc 0.9758\n",
      "Epoch 80: Train Loss 0.0979 | Train Acc 0.9846\n",
      "Epoch 81: Train Loss 0.0983 | Train Acc 0.9824\n",
      "Epoch 82: Train Loss 0.0967 | Train Acc 0.9824\n",
      "Epoch 83: Train Loss 0.1081 | Train Acc 0.9780\n",
      "Epoch 84: Train Loss 0.1390 | Train Acc 0.9648\n",
      "Epoch 85: Train Loss 0.1028 | Train Acc 0.9846\n",
      "Epoch 86: Train Loss 0.1019 | Train Acc 0.9824\n",
      "Epoch 87: Train Loss 0.0992 | Train Acc 0.9780\n",
      "Epoch 88: Train Loss 0.1039 | Train Acc 0.9846\n",
      "Epoch 89: Train Loss 0.1027 | Train Acc 0.9758\n",
      "Epoch 90: Train Loss 0.1095 | Train Acc 0.9736\n",
      "Epoch 91: Train Loss 0.1239 | Train Acc 0.9758\n",
      "Epoch 92: Train Loss 0.1052 | Train Acc 0.9846\n",
      "Epoch 93: Train Loss 0.1170 | Train Acc 0.9714\n",
      "Epoch 94: Train Loss 0.0966 | Train Acc 0.9802\n",
      "Epoch 95: Train Loss 0.1107 | Train Acc 0.9846\n",
      "Epoch 96: Train Loss 0.0947 | Train Acc 0.9824\n",
      "Epoch 97: Train Loss 0.0963 | Train Acc 0.9802\n",
      "Epoch 98: Train Loss 0.1097 | Train Acc 0.9824\n",
      "Epoch 99: Train Loss 0.0957 | Train Acc 0.9824\n",
      "Epoch 100: Train Loss 0.0934 | Train Acc 0.9824\n",
      "Test Loss: 0.2061 | Test Acc: 0.9649\n",
      "63.1578947368421 this is percent 0\n",
      "Predicted 0: 63.16%\n",
      "Predicted 1: 36.84%\n",
      "\n",
      "--- Fold 4 ---\n",
      "Epoch 1: Train Loss 1.3211 | Train Acc 0.4330\n",
      "Epoch 2: Train Loss 1.1914 | Train Acc 0.3714\n",
      "Epoch 3: Train Loss 1.0989 | Train Acc 0.3714\n",
      "Epoch 4: Train Loss 0.9904 | Train Acc 0.3714\n",
      "Epoch 5: Train Loss 0.8014 | Train Acc 0.4022\n",
      "Epoch 6: Train Loss 0.6412 | Train Acc 0.7978\n",
      "Epoch 7: Train Loss 0.4889 | Train Acc 0.9099\n",
      "Epoch 8: Train Loss 0.4016 | Train Acc 0.9165\n",
      "Epoch 9: Train Loss 0.3089 | Train Acc 0.9297\n",
      "Epoch 10: Train Loss 0.2212 | Train Acc 0.9363\n",
      "Epoch 11: Train Loss 0.2415 | Train Acc 0.9451\n",
      "Epoch 12: Train Loss 0.1966 | Train Acc 0.9582\n",
      "Epoch 13: Train Loss 0.2094 | Train Acc 0.9429\n",
      "Epoch 14: Train Loss 0.1823 | Train Acc 0.9516\n",
      "Epoch 15: Train Loss 0.1646 | Train Acc 0.9626\n",
      "Epoch 16: Train Loss 0.1646 | Train Acc 0.9582\n",
      "Epoch 17: Train Loss 0.1577 | Train Acc 0.9692\n",
      "Epoch 18: Train Loss 0.1514 | Train Acc 0.9560\n",
      "Epoch 19: Train Loss 0.1730 | Train Acc 0.9604\n",
      "Epoch 20: Train Loss 0.2081 | Train Acc 0.9363\n",
      "Epoch 21: Train Loss 0.1531 | Train Acc 0.9714\n",
      "Epoch 22: Train Loss 0.1504 | Train Acc 0.9758\n",
      "Epoch 23: Train Loss 0.1441 | Train Acc 0.9670\n",
      "Epoch 24: Train Loss 0.1362 | Train Acc 0.9648\n",
      "Epoch 25: Train Loss 0.1491 | Train Acc 0.9692\n",
      "Epoch 26: Train Loss 0.1623 | Train Acc 0.9648\n",
      "Epoch 27: Train Loss 0.1770 | Train Acc 0.9626\n",
      "Epoch 28: Train Loss 0.1281 | Train Acc 0.9692\n",
      "Epoch 29: Train Loss 0.1499 | Train Acc 0.9582\n",
      "Epoch 30: Train Loss 0.1593 | Train Acc 0.9692\n",
      "Epoch 31: Train Loss 0.1615 | Train Acc 0.9692\n",
      "Epoch 32: Train Loss 0.1523 | Train Acc 0.9648\n",
      "Epoch 33: Train Loss 0.1362 | Train Acc 0.9560\n",
      "Epoch 34: Train Loss 0.1294 | Train Acc 0.9802\n",
      "Epoch 35: Train Loss 0.1257 | Train Acc 0.9802\n",
      "Epoch 36: Train Loss 0.1475 | Train Acc 0.9692\n",
      "Epoch 37: Train Loss 0.1204 | Train Acc 0.9714\n",
      "Epoch 38: Train Loss 0.1097 | Train Acc 0.9802\n",
      "Epoch 39: Train Loss 0.1161 | Train Acc 0.9802\n",
      "Epoch 40: Train Loss 0.1097 | Train Acc 0.9780\n",
      "Epoch 41: Train Loss 0.1147 | Train Acc 0.9802\n",
      "Epoch 42: Train Loss 0.1070 | Train Acc 0.9802\n",
      "Epoch 43: Train Loss 0.1073 | Train Acc 0.9780\n",
      "Epoch 44: Train Loss 0.1088 | Train Acc 0.9758\n",
      "Epoch 45: Train Loss 0.1068 | Train Acc 0.9802\n",
      "Epoch 46: Train Loss 0.1034 | Train Acc 0.9846\n",
      "Epoch 47: Train Loss 0.1102 | Train Acc 0.9868\n",
      "Epoch 48: Train Loss 0.1083 | Train Acc 0.9692\n",
      "Epoch 49: Train Loss 0.0992 | Train Acc 0.9890\n",
      "Epoch 50: Train Loss 0.1058 | Train Acc 0.9780\n",
      "Epoch 51: Train Loss 0.0925 | Train Acc 0.9824\n",
      "Epoch 52: Train Loss 0.1250 | Train Acc 0.9736\n",
      "Epoch 53: Train Loss 0.1208 | Train Acc 0.9846\n",
      "Epoch 54: Train Loss 0.1416 | Train Acc 0.9736\n",
      "Epoch 55: Train Loss 0.1155 | Train Acc 0.9714\n",
      "Epoch 56: Train Loss 0.1184 | Train Acc 0.9758\n",
      "Epoch 57: Train Loss 0.1077 | Train Acc 0.9846\n",
      "Epoch 58: Train Loss 0.0976 | Train Acc 0.9780\n",
      "Epoch 59: Train Loss 0.0980 | Train Acc 0.9802\n",
      "Epoch 60: Train Loss 0.0834 | Train Acc 0.9846\n",
      "Epoch 61: Train Loss 0.0886 | Train Acc 0.9824\n",
      "Epoch 62: Train Loss 0.0814 | Train Acc 0.9868\n",
      "Epoch 63: Train Loss 0.0839 | Train Acc 0.9890\n",
      "Epoch 64: Train Loss 0.0824 | Train Acc 0.9868\n",
      "Epoch 65: Train Loss 0.0848 | Train Acc 0.9868\n",
      "Epoch 66: Train Loss 0.0759 | Train Acc 0.9868\n",
      "Epoch 67: Train Loss 0.0819 | Train Acc 0.9868\n",
      "Epoch 68: Train Loss 0.0998 | Train Acc 0.9780\n",
      "Epoch 69: Train Loss 0.0692 | Train Acc 0.9868\n",
      "Epoch 70: Train Loss 0.0853 | Train Acc 0.9846\n",
      "Epoch 71: Train Loss 0.0745 | Train Acc 0.9868\n",
      "Epoch 72: Train Loss 0.0780 | Train Acc 0.9846\n",
      "Epoch 73: Train Loss 0.0705 | Train Acc 0.9868\n",
      "Epoch 74: Train Loss 0.0734 | Train Acc 0.9868\n",
      "Epoch 75: Train Loss 0.0701 | Train Acc 0.9868\n",
      "Epoch 76: Train Loss 0.0716 | Train Acc 0.9846\n",
      "Epoch 77: Train Loss 0.0646 | Train Acc 0.9890\n",
      "Epoch 78: Train Loss 0.1078 | Train Acc 0.9758\n",
      "Epoch 79: Train Loss 0.0700 | Train Acc 0.9912\n",
      "Epoch 80: Train Loss 0.0821 | Train Acc 0.9868\n",
      "Epoch 81: Train Loss 0.0970 | Train Acc 0.9780\n",
      "Epoch 82: Train Loss 0.1232 | Train Acc 0.9670\n",
      "Epoch 83: Train Loss 0.0821 | Train Acc 0.9890\n",
      "Epoch 84: Train Loss 0.0642 | Train Acc 0.9868\n",
      "Epoch 85: Train Loss 0.0673 | Train Acc 0.9846\n",
      "Epoch 86: Train Loss 0.0616 | Train Acc 0.9868\n",
      "Epoch 87: Train Loss 0.0588 | Train Acc 0.9912\n",
      "Epoch 88: Train Loss 0.0546 | Train Acc 0.9912\n",
      "Epoch 89: Train Loss 0.0702 | Train Acc 0.9846\n",
      "Epoch 90: Train Loss 0.0914 | Train Acc 0.9802\n",
      "Epoch 91: Train Loss 0.0698 | Train Acc 0.9912\n",
      "Epoch 92: Train Loss 0.0635 | Train Acc 0.9912\n",
      "Epoch 93: Train Loss 0.0617 | Train Acc 0.9890\n",
      "Epoch 94: Train Loss 0.0690 | Train Acc 0.9890\n",
      "Epoch 95: Train Loss 0.0886 | Train Acc 0.9780\n",
      "Epoch 96: Train Loss 0.1111 | Train Acc 0.9692\n",
      "Epoch 97: Train Loss 0.1090 | Train Acc 0.9714\n",
      "Epoch 98: Train Loss 0.0731 | Train Acc 0.9758\n",
      "Epoch 99: Train Loss 0.0560 | Train Acc 0.9890\n",
      "Epoch 100: Train Loss 0.0504 | Train Acc 0.9912\n",
      "Test Loss: 0.6066 | Test Acc: 0.9737\n",
      "63.1578947368421 this is percent 0\n",
      "Predicted 0: 63.16%\n",
      "Predicted 1: 36.84%\n",
      "\n",
      "--- Fold 5 ---\n",
      "Epoch 1: Train Loss 1.3304 | Train Acc 0.4386\n",
      "Epoch 2: Train Loss 1.2620 | Train Acc 0.3728\n",
      "Epoch 3: Train Loss 1.1804 | Train Acc 0.3728\n",
      "Epoch 4: Train Loss 1.0720 | Train Acc 0.3728\n",
      "Epoch 5: Train Loss 0.8412 | Train Acc 0.3904\n",
      "Epoch 6: Train Loss 0.5920 | Train Acc 0.7895\n",
      "Epoch 7: Train Loss 0.4417 | Train Acc 0.9189\n",
      "Epoch 8: Train Loss 0.3203 | Train Acc 0.9342\n",
      "Epoch 9: Train Loss 0.2285 | Train Acc 0.9386\n",
      "Epoch 10: Train Loss 0.2022 | Train Acc 0.9430\n",
      "Epoch 11: Train Loss 0.1781 | Train Acc 0.9452\n",
      "Epoch 12: Train Loss 0.1628 | Train Acc 0.9518\n",
      "Epoch 13: Train Loss 0.1876 | Train Acc 0.9386\n",
      "Epoch 14: Train Loss 0.1580 | Train Acc 0.9583\n",
      "Epoch 15: Train Loss 0.1406 | Train Acc 0.9627\n",
      "Epoch 16: Train Loss 0.1399 | Train Acc 0.9693\n",
      "Epoch 17: Train Loss 0.1274 | Train Acc 0.9715\n",
      "Epoch 18: Train Loss 0.1192 | Train Acc 0.9737\n",
      "Epoch 19: Train Loss 0.1157 | Train Acc 0.9627\n",
      "Epoch 20: Train Loss 0.1277 | Train Acc 0.9627\n",
      "Epoch 21: Train Loss 0.1440 | Train Acc 0.9627\n",
      "Epoch 22: Train Loss 0.1186 | Train Acc 0.9671\n",
      "Epoch 23: Train Loss 0.1077 | Train Acc 0.9846\n",
      "Epoch 24: Train Loss 0.1270 | Train Acc 0.9693\n",
      "Epoch 25: Train Loss 0.1079 | Train Acc 0.9649\n",
      "Epoch 26: Train Loss 0.1105 | Train Acc 0.9649\n",
      "Epoch 27: Train Loss 0.1116 | Train Acc 0.9825\n",
      "Epoch 28: Train Loss 0.1190 | Train Acc 0.9715\n",
      "Epoch 29: Train Loss 0.1230 | Train Acc 0.9737\n",
      "Epoch 30: Train Loss 0.1422 | Train Acc 0.9649\n",
      "Epoch 31: Train Loss 0.0984 | Train Acc 0.9671\n",
      "Epoch 32: Train Loss 0.1131 | Train Acc 0.9737\n",
      "Epoch 33: Train Loss 0.0927 | Train Acc 0.9825\n",
      "Epoch 34: Train Loss 0.1413 | Train Acc 0.9452\n",
      "Epoch 35: Train Loss 0.1308 | Train Acc 0.9605\n",
      "Epoch 36: Train Loss 0.0889 | Train Acc 0.9759\n",
      "Epoch 37: Train Loss 0.0978 | Train Acc 0.9693\n",
      "Epoch 38: Train Loss 0.1065 | Train Acc 0.9737\n",
      "Epoch 39: Train Loss 0.1231 | Train Acc 0.9715\n",
      "Epoch 40: Train Loss 0.0872 | Train Acc 0.9737\n",
      "Epoch 41: Train Loss 0.1054 | Train Acc 0.9715\n",
      "Epoch 42: Train Loss 0.0865 | Train Acc 0.9825\n",
      "Epoch 43: Train Loss 0.0987 | Train Acc 0.9737\n",
      "Epoch 44: Train Loss 0.1112 | Train Acc 0.9671\n",
      "Epoch 45: Train Loss 0.1028 | Train Acc 0.9846\n",
      "Epoch 46: Train Loss 0.0951 | Train Acc 0.9715\n",
      "Epoch 47: Train Loss 0.0830 | Train Acc 0.9781\n",
      "Epoch 48: Train Loss 0.0974 | Train Acc 0.9737\n",
      "Epoch 49: Train Loss 0.1037 | Train Acc 0.9715\n",
      "Epoch 50: Train Loss 0.1319 | Train Acc 0.9649\n",
      "Epoch 51: Train Loss 0.1382 | Train Acc 0.9715\n",
      "Epoch 52: Train Loss 0.1093 | Train Acc 0.9605\n",
      "Epoch 53: Train Loss 0.0961 | Train Acc 0.9781\n",
      "Epoch 54: Train Loss 0.1267 | Train Acc 0.9649\n",
      "Epoch 55: Train Loss 0.0887 | Train Acc 0.9715\n",
      "Epoch 56: Train Loss 0.0856 | Train Acc 0.9781\n",
      "Epoch 57: Train Loss 0.0861 | Train Acc 0.9715\n",
      "Epoch 58: Train Loss 0.0819 | Train Acc 0.9781\n",
      "Epoch 59: Train Loss 0.0829 | Train Acc 0.9781\n",
      "Epoch 60: Train Loss 0.0937 | Train Acc 0.9737\n",
      "Epoch 61: Train Loss 0.0974 | Train Acc 0.9693\n",
      "Epoch 62: Train Loss 0.0952 | Train Acc 0.9781\n",
      "Epoch 63: Train Loss 0.0811 | Train Acc 0.9825\n",
      "Epoch 64: Train Loss 0.0827 | Train Acc 0.9715\n",
      "Epoch 65: Train Loss 0.1176 | Train Acc 0.9671\n",
      "Epoch 66: Train Loss 0.1091 | Train Acc 0.9803\n",
      "Epoch 67: Train Loss 0.0824 | Train Acc 0.9781\n",
      "Epoch 68: Train Loss 0.0778 | Train Acc 0.9781\n",
      "Epoch 69: Train Loss 0.0768 | Train Acc 0.9846\n",
      "Epoch 70: Train Loss 0.0912 | Train Acc 0.9737\n",
      "Epoch 71: Train Loss 0.0741 | Train Acc 0.9803\n",
      "Epoch 72: Train Loss 0.0703 | Train Acc 0.9781\n",
      "Epoch 73: Train Loss 0.0832 | Train Acc 0.9671\n",
      "Epoch 74: Train Loss 0.0923 | Train Acc 0.9803\n",
      "Epoch 75: Train Loss 0.1055 | Train Acc 0.9561\n",
      "Epoch 76: Train Loss 0.1535 | Train Acc 0.9759\n",
      "Epoch 77: Train Loss 0.1269 | Train Acc 0.9671\n",
      "Epoch 78: Train Loss 0.0750 | Train Acc 0.9781\n",
      "Epoch 79: Train Loss 0.0781 | Train Acc 0.9671\n",
      "Epoch 80: Train Loss 0.0862 | Train Acc 0.9803\n",
      "Epoch 81: Train Loss 0.0788 | Train Acc 0.9759\n",
      "Epoch 82: Train Loss 0.0752 | Train Acc 0.9803\n",
      "Epoch 83: Train Loss 0.0858 | Train Acc 0.9825\n",
      "Epoch 84: Train Loss 0.0838 | Train Acc 0.9715\n",
      "Epoch 85: Train Loss 0.0899 | Train Acc 0.9781\n",
      "Epoch 86: Train Loss 0.0742 | Train Acc 0.9759\n",
      "Epoch 87: Train Loss 0.0771 | Train Acc 0.9737\n",
      "Epoch 88: Train Loss 0.0871 | Train Acc 0.9759\n",
      "Epoch 89: Train Loss 0.0954 | Train Acc 0.9803\n",
      "Epoch 90: Train Loss 0.0698 | Train Acc 0.9781\n",
      "Epoch 91: Train Loss 0.0878 | Train Acc 0.9803\n",
      "Epoch 92: Train Loss 0.1110 | Train Acc 0.9671\n",
      "Epoch 93: Train Loss 0.0852 | Train Acc 0.9605\n",
      "Epoch 94: Train Loss 0.0762 | Train Acc 0.9868\n",
      "Epoch 95: Train Loss 0.0856 | Train Acc 0.9737\n",
      "Epoch 96: Train Loss 0.0723 | Train Acc 0.9803\n",
      "Epoch 97: Train Loss 0.0947 | Train Acc 0.9737\n",
      "Epoch 98: Train Loss 0.0806 | Train Acc 0.9715\n",
      "Epoch 99: Train Loss 0.0692 | Train Acc 0.9825\n",
      "Epoch 100: Train Loss 0.0805 | Train Acc 0.9715\n",
      "Test Loss: 0.2940 | Test Acc: 0.9912\n",
      "66.3716814159292 this is percent 0\n",
      "Predicted 0: 66.37%\n",
      "Predicted 1: 33.63%\n"
     ]
    }
   ],
   "source": [
    "fold_results, models = train_with_stratified_kfold(X_np,y_np,model_1,30,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1022,
   "id": "0f23a452-c62a-4cda-9192-26e98b015c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.20836834148544686, 0.9736842105263158), (0.13208506143602886, 0.9824561403508771), (0.20606886708226643, 0.9649122807017544), (0.6065831927556071, 0.9736842105263158), (0.29395549117991354, 0.9911504424778761)]\n"
     ]
    }
   ],
   "source": [
    "print(fold_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1023,
   "id": "1a0519cc-7b88-4bd3-adf7-d9e5a116ac67",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = models[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1024,
   "id": "767f2608-ca0d-40c3-8318-b2b05bf108ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BinaryClassifier(\n",
      "  (network): Sequential(\n",
      "    (0): Linear(in_features=30, out_features=22, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=22, out_features=31, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=31, out_features=44, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=44, out_features=62, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=62, out_features=88, bias=True)\n",
      "    (9): ReLU()\n",
      "    (10): Linear(in_features=88, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b23fef-fad8-4022-ac00-578667fbdffc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
